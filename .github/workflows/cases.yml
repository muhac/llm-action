name: Run LLMs

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:

  docker:
    name: Run in Docker
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Free disk space
      uses: jlumbroso/free-disk-space@main
      with:
        tool-cache: true

    - name: Pull Image
      run: docker pull muhac/jupyter-pytorch:v2.5.1-lts

    - name: Test Env
      run: |
        ls
        docker run -v ./:/srv \
        muhac/jupyter-pytorch:v2.5.1-lts \
        bash -i -c "tree /srv"

    - name: Run LLM
      run: |
        docker run -v ./:/srv \
        muhac/jupyter-pytorch:v2.5.1-lts \
        bash -i -c "python /srv/demo.py"

  vllm:
    name: Run by vLLM
    runs-on: ubuntu-latest

    steps:
    - name: Checkout
      uses: actions/checkout@v4

  # - name: Free disk space
  #   uses: jlumbroso/free-disk-space@main

    - name: Checkout vLLM
      uses: actions/checkout@v4
      with:
        repository: "vllm-project/vllm"
        ref: "v0.7.2"

    - name: Install dependencies
      run: |
        sudo apt-get update  -y
        sudo apt-get install -y gcc-12 g++-12 libnuma-dev
        sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 10 --slave /usr/bin/g++ g++ /usr/bin/g++-12

    - name: Build vLLM
      run: |
        pip install --upgrade pip
        pip install "cmake>=3.26" wheel packaging ninja "setuptools-scm>=8" numpy
        pip install -v -r requirements-cpu.txt --extra-index-url https://download.pytorch.org/whl/cpu
        sudo -E VLLM_TARGET_DEVICE=cpu python setup.py install

    - name: Install libraries
      run: |
        pip install openai

    - name: Run models
      run: |
        vllm serve Qwen/Qwen2.5-1.5B-Instruct &> vllm.log &
        while ! grep -q "running on http://0.0.0.0:8000" vllm.log; do
            sleep 1
        done
        cat vllm.log
        curl --retry 5 --retry-delay 10 http://localhost:8000/v1/models

    - name: Demo Chat
      run: |
        curl http://localhost:8000/v1/chat/completions \
        -H "Content-Type: application/json" \
        -d '{
            "model": "Qwen/Qwen2.5-1.5B-Instruct",
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Who won the world series in 2020?"}
            ]
        }'
